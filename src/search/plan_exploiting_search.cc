#include "plan_exploiting_search.h"

#include "evaluation_context.h"
#include "evaluation_result.h"
#include "globals.h"
#include "heuristic.h"
#include "option_parser.h"
#include "plan_extractable_heuristic.h"
#include "plugin.h"
#include "successor_generator.h"
#include "search_space.h"

#include "task_proxy.h"
#include "./delete_relaxation/delete_relaxation_heuristic.h"
#include "./delete_relaxation/delete_relaxation_heuristic.h"

#include <cassert>
#include <cstdlib>
#include <set>
#include <stdexcept>
using namespace std;

PlanExploitingSearch::PlanExploitingSearch(const Options &opts) :
		SearchEngine(opts), reopen_closed_nodes(
				opts.get<bool>("reopen_closed")), use_multi_path_dependence(
				opts.get<bool>("mpd")), open_list(
				opts.get<OpenList<StateID> *>("open")), num_replans(0) {

	vector<Heuristic *> temp_heuristics(opts.get_list<Heuristic *>("evals"));
	for (Heuristic * h : opts.get_list<Heuristic *>("evals")) {
		PlanExtractableHeuristic *peh =
				dynamic_cast<PlanExtractableHeuristic *>(h);
		// dynamic cast guaranteed to work because it is checked while parsing
		heuristics.push_back(peh);
	}
}

void PlanExploitingSearch::initialize() {
	cout << "Conducting best first search"
			<< (reopen_closed_nodes ? " with" : " without")
			<< " reopening closed nodes, (real) bound = " << bound << endl;
	if (use_multi_path_dependence)
		cout << "Using multi-path dependence (LM-A*)" << endl;

	assert(open_list);
	assert(!heuristics.empty());

	const GlobalState &initial_state = g_initial_state();
	// Note: we consider the initial state as reached by a preferred
	// operator.
	EvaluationContext eval_context(initial_state, 0, true, &statistics);

	statistics.inc_evaluated_states();

	if (open_list->is_dead_end(eval_context)) {
		cout << "Initial state is a dead end." << endl;
	} else {
		if (search_progress.check_progress(eval_context))
			print_checkpoint_line(0);
		SearchNode node = search_space.get_node(initial_state);
		node.open_initial();

		open_list->insert(eval_context, initial_state.get_id());
	}

	print_initial_h_values(eval_context);
}

void PlanExploitingSearch::print_checkpoint_line(int g) const {
	cout << "[g=" << g << ", ";
	statistics.print_basic_statistics();
	cout << "]" << endl;
}

void PlanExploitingSearch::print_statistics() const {
	statistics.print_detailed_statistics();
	search_space.print_statistics();
}

SearchStatus PlanExploitingSearch::step() {
	pair<SearchNode, bool> n = fetch_next_node();
	if (!n.second) {
		cout << "\n\n\nNumber of replans: " << num_replans << endl;
		return FAILED;
	}
	SearchNode node = n.first;

	GlobalState start_state = node.get_state();
// 	State state = convert_global_state(initial_state);

	if (check_goal_and_set_plan(start_state)) {
		cout << "\n\n\nNumber of replans: " << num_replans << endl;
		return SOLVED;
	}

	bool is_preferred = false;
	EvaluationContext eval_context(start_state, node.get_g(), is_preferred,
			&statistics);

	for (PlanExtractableHeuristic *heuristic : heuristics) {
		GlobalState probed = start_state;
		GlobalState probee = probed;
		int new_g_cost = node.get_g();
		int count_ops = 0;
		vector<const GlobalOperator*> ops2 = heuristic->extract_plan();
		cout << "\n\n\nExecuting Ops..." << ops2.size() << endl;
		for (const GlobalOperator *op : ops2) {
			//probee = probe_state.get_successor(*op)
			if (op->is_applicable(probed)) {
				op->dump();
				++count_ops;
				probee = g_state_registry->get_successor_state(probed, *op);

				SearchNode next_node = search_space.get_node(probee);

				if (next_node.is_new()) {
					next_node.open(node, op);

					// Set information to trace solution path when found
					next_node.open(search_space.get_node(probed), op);
//					next_node.info.creating_operator = op;
//					next_node.info.parent_state_id = probed.get_id();
//				} else {
//					cout << "break";
//					break;
				}

				new_g_cost += get_adjusted_cost(*op);
				heuristic->reach_state(probed, *op, probee);
				probed = probee;
			}
		}

		if (!(probed == start_state)) {
			++num_replans;
			EvaluationContext eval_context(probed, new_g_cost, is_preferred,
					&statistics);
			EvaluationResult result = heuristic->compute_result(eval_context);
			statistics.inc_evaluated_states();
			open_list->insert(eval_context, probed.get_id()); // this would need to change to an openlist of State instead of StateID
		}
//		else {
//			cout << "Did not take any action" << endl;
//			cout << "End state in step" << endl;
//
//			for (size_t var_id = 0; var_id < g_fact_names.size(); ++var_id) {
//				for (size_t var_value = 0;
//						var_value < g_fact_names[var_id].size(); ++var_value) {
//					if (probed[var_id] == (int) var_value) {
//						FactProxy fact(*g_root_task(), var_id, var_value);
//						cout << LPVariableProxy(fact).get_details() << endl;
//					}
//				}
//			}
//		}
	}

	return IN_PROGRESS;
}

pair<SearchNode, bool> PlanExploitingSearch::fetch_next_node() {
	/* TODO: The bulk of this code deals with multi-path dependence,
	 which is a bit unfortunate since that is a special case that
	 makes the common case look more complicated than it would need
	 to be. We could refactor this by implementing multi-path
	 dependence as a separate search algorithm that wraps the "usual"
	 search algorithm and adds the extra processing in the desired
	 places. I think this would lead to much cleaner code. */

//	cout << "Size of open list before fetching = " << open_list->size() << endl;
	while (true) {
		if (open_list->empty()) {
			cout
					<< "OpenList empty!. Completely explored state space -- no solution!"
					<< endl;
			// HACK! HACK! we do this because SearchNode has no default/copy constructor
			SearchNode dummy_node = search_space.get_node(g_initial_state());
			return make_pair(dummy_node, false);
		}
		vector<int> last_key_removed;
		StateID id = open_list->remove_min(
				use_multi_path_dependence ? &last_key_removed : nullptr);
		// TODO is there a way we can avoid creating the state here and then
		//      recreate it outside of this function with node.get_state()?
		//      One way would be to store GlobalState objects inside SearchNodes
		//      instead of StateIDs
		GlobalState s = g_state_registry->lookup_state(id);
		SearchNode node = search_space.get_node(s);

		vector<const GlobalOperator *> applicable_ops;
		g_successor_generator->generate_applicable_ops(s, applicable_ops);

		if (node.is_closed())
			continue;

		if (use_multi_path_dependence) {
			assert(last_key_removed.size() == 2);
			if (node.is_dead_end())
				continue;
			int pushed_h = last_key_removed[1];

			if (!node.is_closed()) {
				EvaluationContext eval_context(node.get_state(), node.get_g(),
						false, &statistics);

				if (open_list->is_dead_end(eval_context)) {
					node.mark_as_dead_end();
					statistics.inc_dead_ends();
					continue;
				}
				if (pushed_h
						< eval_context.get_result(heuristics[0]).get_h_value()) {
					assert(node.is_open());
					open_list->insert(eval_context, node.get_state_id());
					continue;
				}
			}
		}

		node.close();
		assert(!node.is_dead_end());
		statistics.inc_expanded();
		return make_pair(node, true);
	}
}

void PlanExploitingSearch::reward_progress() {
// Boost the "preferred operator" open lists somewhat whenever
// one of the heuristics finds a state with a new best h value.
	open_list->boost_preferred();
}

void PlanExploitingSearch::dump_search_space() const {
	search_space.dump();
}

static SearchEngine *_parse_greedy(OptionParser &parser) {
	parser.document_synopsis(
			"Search that executes as many actions as possible from the heuristic's computation of the ordered plan",
			"");

	parser.add_list_option<Heuristic *>("evals", "plan extractable heuristics");
	SearchEngine::add_options_to_parser(parser);

	Options opts = parser.parse();
	opts.verify_list_non_empty<Heuristic *>("evals");

	PlanExploitingSearch *engine = nullptr;
	if (!parser.dry_run()) {
		// Convert heuristics to PlanExtractableHeuristics
		vector<Heuristic *> evals = opts.get_list<Heuristic *>("evals");
		for (Heuristic *h : evals) {
			PlanExtractableHeuristic *peh =
					dynamic_cast<PlanExtractableHeuristic *>(h);
			if (peh == nullptr) {
				cout
						<< "Input Error: Heuristic Evaluators were not of type PlanExtractableHeuristic"
						<< endl;
				exit(-1);
			}
		}
		OpenList<StateID> *open;
		if ((evals.size() == 1)) {
			open = new StandardScalarOpenList<StateID>(evals[0], false);
		} else {
			vector<OpenList<StateID> *> inner_lists;
			for (Heuristic *evaluator : evals) {
				inner_lists.push_back(
						new StandardScalarOpenList<StateID>(evaluator, false));
			}
			open = new AlternationOpenList<StateID>(inner_lists,
					opts.get<int>("boost"));
		}

		opts.set("open", open);
		opts.set("reopen_closed", false);
		opts.set("mpd", false);
		opts.set("evals", evals);
		engine = new PlanExploitingSearch(opts);
	}
	return engine;
}

static Plugin<SearchEngine> _plugin_greedy("exploit_greedy", _parse_greedy);
